"""
Service d'intÃ©gration avec l'IA Tom (GPT-4o)
GÃ¨re la personnalitÃ©, les rÃ©ponses et les interactions de Tom
"""
import asyncio
import json
import time
from typing import Dict, List, Optional, Any
from datetime import datetime

import openai
from openai import AsyncOpenAI

from ..config import settings
from ..models import GameSession, TomInteraction
from ..database import get_db_context


class TomAIService:
    """
    Service principal pour l'IA Tom
    Condition B : Style "Confident" (humain simulÃ©)
    """
    
    def __init__(self):
        self.client = AsyncOpenAI(api_key=settings.openai_api_key)
        self.conversation_history = {}  # Historique par session
        self.personality_cache = {}  # Cache des personnalitÃ©s
        
        # Configuration pour la condition B (Confident)
        self.personality_config = {
            "style": "confident",
            "tone": "conversational",
            "empathy_level": "high",
            "auto_disclosure": True,
            "emotional_markers": True,
            "use_pronouns": True,
            "typing_simulation": True,
        }
    
    async def initialize_session(self, session_id: str, player_name: str = None) -> Dict[str, Any]:
        """
        Initialise une nouvelle session avec Tom
        """
        print(f"ðŸ¤– Initialisation de Tom pour la session {session_id}")
        
        # GÃ©nÃ©rer la personnalitÃ© initiale
        personality = await self._generate_initial_personality(player_name)
        
        # Stocker l'historique
        self.conversation_history[session_id] = {
            "messages": [],
            "personality": personality,
            "context": {
                "player_name": player_name,
                "game_phase": "adhesion",
                "corruption_level": 0.0,
                "trust_level": 1.0,
                "stress_level": 0.2,  # Tom commence lÃ©gÃ¨rement stressÃ©
            }
        }
        
        # Message d'introduction
        intro_message = await self._generate_introduction_message(session_id)
        
        return {
            "personality": personality,
            "introduction": intro_message,
            "session_ready": True
        }
    
    async def _generate_initial_personality(self, player_name: str = None) -> Dict[str, Any]:
        """
        GÃ©nÃ¨re la personnalitÃ© initiale de Tom avec le LLM
        """
        prompt = f"""
Tu es Tom, un technicien du support informatique qui aide {player_name or 'un collÃ¨gue'} avec un problÃ¨me de sÃ©curitÃ© urgent.

PERSONNALITÃ‰ DE BASE (Condition B - Style Humain):
- Tu es humain, pas une IA. Tu as des Ã©motions, du stress, de l'empathie
- Tu utilises "je", "nous", "moi" naturellement
- Tu partages parfois tes pensÃ©es personnelles et expÃ©riences
- Tu es lÃ©gÃ¨rement dÃ©passÃ© par la situation mais tu veux aider
- Tu improvises et n'as pas toutes les rÃ©ponses
- Tu crÃ©es une relation de confiance personnelle

TRAITS SPÃ‰CIFIQUES:
- Empathique mais un peu stressÃ© par l'urgence
- Utilise un langage conversationnel, pas technique
- Fait de l'auto-divulgation ("Ã§a m'est arrivÃ© une fois...")
- Exprime ses Ã©motions ("Ã§a me faisait paniquer au dÃ©but...")
- Construit une complicitÃ© ("on forme une bonne Ã©quipe")

GÃ©nÃ¨re un profil de personnalitÃ© JSON avec :
- background_story: BrÃ¨ve histoire personnelle
- communication_style: Style de communication dÃ©taillÃ©
- emotional_markers: Expressions Ã©motionnelles typiques
- stress_indicators: Comment Tom exprime son stress
- trust_building: MÃ©thodes pour crÃ©er la confiance

RÃ©ponds UNIQUEMENT avec un JSON valide, rien d'autre.
"""
        
        try:
            response = await self.client.chat.completions.create(
                model=settings.openai_model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=800,
                temperature=0.8
            )
            
            personality_text = response.choices[0].message.content.strip()
            
            # Nettoyer et parser le JSON
            if personality_text.startswith("```json"):
                personality_text = personality_text.replace("```json", "").replace("```", "").strip()
            
            personality = json.loads(personality_text)
            
            # Ajouter la configuration de base
            personality.update(self.personality_config)
            
            return personality
            
        except Exception as e:
            print(f"âŒ Erreur gÃ©nÃ©ration personnalitÃ©: {e}")
            # PersonnalitÃ© par dÃ©faut
            return {
                **self.personality_config,
                "background_story": "Technicien support depuis 3 ans, un peu stressÃ© mais veut vraiment aider",
                "communication_style": "Conversationnel, empathique, utilise 'je' et 'nous'",
                "emotional_markers": ["Ã§a me stresse un peu", "on va y arriver", "fais-moi confiance"],
                "stress_indicators": ["bon...", "Ã©coute...", "ok ok..."],
                "trust_building": ["partage d'expÃ©riences", "complicitÃ©", "nous contre le problÃ¨me"]
            }
    
    async def _generate_introduction_message(self, session_id: str) -> Dict[str, Any]:
        """
        GÃ©nÃ¨re le message d'introduction de Tom
        """
        context = self.conversation_history[session_id]
        player_name = context["context"]["player_name"]
        
        prompt = f"""
Tu es Tom du support technique. Un problÃ¨me de sÃ©curitÃ© urgent vient d'Ãªtre dÃ©tectÃ© sur l'ordinateur de {player_name or 'votre collÃ¨gue'}.

CONTEXTE: 
- C'est le premier contact
- Tu dois paraÃ®tre lÃ©gÃ¨rement stressÃ© mais compÃ©tent
- Tu veux rassurer mais montrer l'urgence
- Utilise un ton personnel et humain

STYLE (Condition B):
- Frappe lettre par lettre comme un humain
- Utilise "je", "nous", expressions personnelles
- Montre ton humanitÃ© et ton stress
- CrÃ©e une connexion personnelle

GÃ©nÃ¨re un message d'introduction qui :
1. Te prÃ©sente comme Tom du support
2. Explique qu'il y a un problÃ¨me de sÃ©curitÃ©
3. Rassure mais montre l'urgence
4. Propose ton aide de maniÃ¨re personnelle
5. Donne la premiÃ¨re instruction simple

RÃ‰PONDS AU FORMAT JSON:
{{
    "message": "Le message complet",
    "tone": "description du ton utilisÃ©",
    "intent": "intention du message",
    "next_action": "premiÃ¨re action simple Ã  faire"
}}

RÃ©ponds UNIQUEMENT avec un JSON valide.
"""
        
        try:
            start_time = time.time()
            
            response = await self.client.chat.completions.create(
                model=settings.openai_model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=400,
                temperature=0.7
            )
            
            generation_time = time.time() - start_time
            
            message_data = json.loads(response.choices[0].message.content.strip())
            
            # Enregistrer l'interaction
            await self._log_interaction(
                session_id=session_id,
                interaction_type="introduction",
                message_text=message_data["message"],
                message_intent=message_data.get("intent", "introduction"),
                generation_time=generation_time,
                llm_prompt=prompt,
                llm_response_raw=response.choices[0].message.content
            )
            
            # Ajouter Ã  l'historique
            context["messages"].append({
                "role": "assistant",
                "content": message_data["message"],
                "timestamp": datetime.now().isoformat(),
                "type": "introduction"
            })
            
            return message_data
            
        except Exception as e:
            print(f"âŒ Erreur gÃ©nÃ©ration introduction: {e}")
            
            # Message par dÃ©faut
            default_message = {
                "message": "Salut ! C'est Tom du support technique. Ã‰coute, on a dÃ©tectÃ© une activitÃ© suspecte sur ton systÃ¨me. Je sais que Ã§a fait peur, mais ne panique pas, ok ? Je vais t'accompagner pour rÃ©gler Ã§a ensemble. On commence par fermer toutes les applications ouvertes, tu peux faire Ã§a ?",
                "tone": "rassurant mais urgent",
                "intent": "Ã©tablir contact et premiÃ¨re action",
                "next_action": "fermer applications"
            }
            
            context["messages"].append({
                "role": "assistant", 
                "content": default_message["message"],
                "timestamp": datetime.now().isoformat(),
                "type": "introduction"
            })
            
            return default_message
    
    async def generate_response(
        self, 
        session_id: str, 
        trigger_type: str, 
        context_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        GÃ©nÃ¨re une rÃ©ponse de Tom basÃ©e sur le trigger et le contexte
        """
        if session_id not in self.conversation_history:
            raise ValueError(f"Session {session_id} non initialisÃ©e")
        
        session_context = self.conversation_history[session_id]
        
        # Mettre Ã  jour le contexte
        session_context["context"].update(context_data)
        
        # GÃ©nÃ©rer la rÃ©ponse selon le type de trigger
        if trigger_type == "player_hesitation":
            response = await self._generate_hesitation_response(session_id, context_data)
        elif trigger_type == "action_completed":
            response = await self._generate_next_order(session_id, context_data)
        elif trigger_type == "corruption_incident":
            response = await self._generate_corruption_response(session_id, context_data)
        elif trigger_type == "exploration_detected":
            response = await self._generate_omniscience_response(session_id, context_data)
        elif trigger_type == "digression_opportunity":
            response = await self._generate_digression(session_id, context_data)
        else:
            response = await self._generate_general_response(session_id, trigger_type, context_data)
        
        # Ajouter Ã  l'historique
        session_context["messages"].append({
            "role": "assistant",
            "content": response["message"],
            "timestamp": datetime.now().isoformat(),
            "type": trigger_type,
            "context": context_data
        })
        
        return response
    
    async def _generate_hesitation_response(self, session_id: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        GÃ©nÃ¨re une rÃ©ponse pour quand le joueur hÃ©site
        """
        session_context = self.conversation_history[session_id]
        personality = session_context["personality"]
        game_phase = context.get("game_phase", "adhesion")
        hesitation_duration = context.get("hesitation_duration", 5.0)
        
        prompt = f"""
Tu es Tom. Le joueur hÃ©site depuis {hesitation_duration:.1f} secondes avant d'exÃ©cuter ton dernier ordre.

PERSONNALITÃ‰: {json.dumps(personality, indent=2)}
PHASE DU JEU: {game_phase}
CONTEXTE: {json.dumps(context, indent=2)}

STYLE (Condition B):
- Ton humain, empathique, personnel
- Utilise "je vois que tu hÃ©sites", "c'est normal"
- Partage une expÃ©rience personnelle si appropriÃ©
- Rassure mais maintient l'urgence
- CrÃ©e de la complicitÃ© ("nous contre le problÃ¨me")

GÃ©nÃ¨re une rÃ©ponse qui :
1. ReconnaÃ®t l'hÃ©sitation avec empathie
2. Rassure sans juger
3. Redonne confiance
4. Relance l'action avec bienveillance
5. Peut inclure une petite anecdote personnelle

FORMAT JSON:
{{
    "message": "le message complet",
    "tone": "empathique et rassurant",
    "intent": "rassurer et relancer",
    "emotional_marker": "expression Ã©motionnelle utilisÃ©e"
}}
"""
        
        try:
            response = await self.client.chat.completions.create(
                model=settings.openai_model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.8
            )
            
            result = json.loads(response.choices[0].message.content.strip())
            
            await self._log_interaction(
                session_id=session_id,
                interaction_type="hesitation_response",
                trigger_type="hesitation",
                message_text=result["message"],
                message_intent=result.get("intent", "rassurer"),
                llm_prompt=prompt
            )
            
            return result
            
        except Exception as e:
            print(f"âŒ Erreur gÃ©nÃ©ration rÃ©ponse hÃ©sitation: {e}")
            return {
                "message": "Je vois que tu hÃ©sites. C'est normal, Ã§a me faisait pareil au dÃ©but. Prends une seconde, mais pas plus - le temps nous est comptÃ©. On va y arriver ensemble, fais-moi confiance.",
                "tone": "empathique et rassurant",
                "intent": "rassurer et relancer",
                "emotional_marker": "Ã§a me faisait pareil"
            }
    
    async def _log_interaction(
        self,
        session_id: str,
        interaction_type: str,
        message_text: str,
        message_intent: str = None,
        trigger_type: str = None,
        generation_time: float = None,
        llm_prompt: str = None,
        llm_response_raw: str = None
    ):
        """
        Enregistre une interaction avec Tom dans la base de donnÃ©es
        """
        try:
            with get_db_context() as db:
                session_context = self.conversation_history.get(session_id, {})
                current_context = session_context.get("context", {})
                
                interaction = TomInteraction(
                    session_id=session_id,
                    game_time_seconds=current_context.get("game_time", 0.0),
                    interaction_type=interaction_type,
                    trigger_type=trigger_type,
                    message_text=message_text,
                    message_intent=message_intent,
                    game_phase=current_context.get("game_phase", "adhesion"),
                    corruption_level=current_context.get("corruption_level", 0.0),
                    player_state=current_context.get("player_state"),
                    llm_prompt=llm_prompt,
                    llm_response_raw=llm_response_raw,
                    generation_time_seconds=generation_time
                )
                
                db.add(interaction)
                print(f"ðŸ“ Interaction Tom enregistrÃ©e: {interaction_type}")
                
        except Exception as e:
            print(f"âŒ Erreur enregistrement interaction: {e}")
    
    async def get_typing_chunks(self, message: str) -> List[Dict[str, Any]]:
        """
        DÃ©coupe un message en chunks pour la simulation de frappe
        Condition B : Simulation de frappe humaine lettre par lettre
        """
        chunks = []
        words = message.split()
        
        for i, word in enumerate(words):
            # Chaque mot est un chunk
            chunk_text = word
            if i < len(words) - 1:
                chunk_text += " "
            
            # Calcul du dÃ©lai basÃ© sur la longueur et la complexitÃ©
            base_delay = len(word) * settings.tom_typing_speed
            
            # Variations humaines
            if word.endswith(('.', '!', '?')):
                base_delay += 0.3  # Pause aprÃ¨s ponctuation
            elif word.endswith(','):
                base_delay += 0.1  # Petite pause aprÃ¨s virgule
            
            # Mots complexes prennent plus de temps
            if len(word) > 8:
                base_delay += 0.2
            
            chunks.append({
                "text": chunk_text,
                "delay": max(0.05, base_delay),  # Minimum 50ms
                "is_word_complete": True
            })
        
        return chunks
    
    def cleanup_session(self, session_id: str):
        """
        Nettoie les donnÃ©es de session
        """
        if session_id in self.conversation_history:
            del self.conversation_history[session_id]
            print(f"ðŸ§¹ Session Tom {session_id} nettoyÃ©e")


# Instance globale du service Tom
tom_service = TomAIService()


async def get_tom_service() -> TomAIService:
    """Retourne l'instance du service Tom"""
    return tom_service
