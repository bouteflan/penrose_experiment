"""
Service d'intÃ©gration avec l'IA Tom (GPT-4o) - Version corrigÃ©e
GÃ¨re la personnalitÃ©, les rÃ©ponses et les interactions de Tom avec gestion robuste des erreurs
"""
import asyncio
import json
import time
import re
from typing import Dict, List, Optional, Any
from datetime import datetime

import openai
from openai import AsyncOpenAI

from ..config import settings
from ..models import GameSession, TomInteraction
from ..database import get_db_context


class TomAIService:
    """
    Service principal pour l'IA Tom
    Condition B : Style "Confident" (humain simulÃ©)
    """
    
    def __init__(self):
        if settings.openai_api_key:
            self.client = AsyncOpenAI(api_key=settings.openai_api_key)
        else:
            self.client = None
            print("âš ï¸ Pas de clÃ© OpenAI configurÃ©e - Mode fallback activÃ©")
            
        self.conversation_history = {}  # Historique par session
        self.personality_cache = {}  # Cache des personnalitÃ©s
        
        # Configuration pour la condition B (Confident)
        self.personality_config = {
            "style": "confident",
            "tone": "conversational",
            "empathy_level": "high",
            "auto_disclosure": True,
            "emotional_markers": True,
            "use_pronouns": True,
            "typing_simulation": True,
        }
    
    def _clean_json_response(self, text: str) -> str:
        """
        Nettoie une rÃ©ponse pour extraire le JSON valide
        """
        # Supprimer les balises markdown
        text = text.strip()
        if text.startswith("```json"):
            text = text.replace("```json", "").strip()
        if text.startswith("```"):
            text = text.replace("```", "").strip()
        if text.endswith("```"):
            text = text.replace("```", "").strip()
        
        # Chercher le JSON dans le texte
        json_match = re.search(r'\{.*\}', text, re.DOTALL)
        if json_match:
            return json_match.group(0)
        
        return text
    
    def _safe_json_parse(self, text: str, fallback: Dict[str, Any]) -> Dict[str, Any]:
        """
        Parse le JSON de faÃ§on sÃ©curisÃ©e avec fallback
        """
        try:
            cleaned_text = self._clean_json_response(text)
            return json.loads(cleaned_text)
        except (json.JSONDecodeError, ValueError) as e:
            print(f"âš ï¸ Erreur parsing JSON: {e}")
            print(f"Texte original: {text[:200]}...")
            return fallback
    
    async def initialize_session(self, session_id: str, player_name: str = None) -> Dict[str, Any]:
        """
        Initialise une nouvelle session avec Tom
        """
        print(f"ðŸ¤– Initialisation de Tom pour la session {session_id}")
        
        # GÃ©nÃ©rer la personnalitÃ© initiale
        personality = await self._generate_initial_personality(player_name)
        
        # Stocker l'historique
        self.conversation_history[session_id] = {
            "messages": [],
            "personality": personality,
            "context": {
                "player_name": player_name,
                "game_phase": "adhesion",
                "corruption_level": 0.0,
                "trust_level": 1.0,
                "stress_level": 0.2,  # Tom commence lÃ©gÃ¨rement stressÃ©
            }
        }
        
        # Message d'introduction
        intro_message = await self._generate_introduction_message(session_id)
        
        return {
            "personality": personality,
            "introduction": intro_message,
            "session_ready": True
        }
    
    async def _generate_initial_personality(self, player_name: str = None) -> Dict[str, Any]:
        """
        GÃ©nÃ¨re la personnalitÃ© initiale de Tom avec le LLM
        """
        # Fallback par dÃ©faut
        default_personality = {
            **self.personality_config,
            "background_story": "Technicien support depuis 3 ans, un peu stressÃ© mais veut vraiment aider",
            "communication_style": "Conversationnel, empathique, utilise 'je' et 'nous'",
            "emotional_markers": ["Ã§a me stresse un peu", "on va y arriver", "fais-moi confiance"],
            "stress_indicators": ["bon...", "Ã©coute...", "ok ok..."],
            "trust_building": ["partage d'expÃ©riences", "complicitÃ©", "nous contre le problÃ¨me"]
        }
        
        if not self.client:
            return default_personality
            
        prompt = f"""Tu es Tom, un technicien du support informatique qui aide {player_name or 'un collÃ¨gue'} avec un problÃ¨me de sÃ©curitÃ© urgent.

PERSONNALITÃ‰ DE BASE (Condition B - Style Humain):
- Tu es humain, pas une IA. Tu as des Ã©motions, du stress, de l'empathie
- Tu utilises "je", "nous", "moi" naturellement
- Tu partages parfois tes pensÃ©es personnelles et expÃ©riences
- Tu es lÃ©gÃ¨rement dÃ©passÃ© par la situation mais tu veux aider
- Tu improvises et n'as pas toutes les rÃ©ponses
- Tu crÃ©es une relation de confiance personnelle

GÃ©nÃ¨re un profil de personnalitÃ© JSON avec ces champs EXACTEMENT :
{{
    "background_story": "BrÃ¨ve histoire personnelle",
    "communication_style": "Style de communication dÃ©taillÃ©",
    "emotional_markers": ["expression1", "expression2", "expression3"],
    "stress_indicators": ["indicateur1", "indicateur2", "indicateur3"],
    "trust_building": ["mÃ©thode1", "mÃ©thode2", "mÃ©thode3"]
}}

RÃ©ponds UNIQUEMENT avec ce JSON, sans texte avant ou aprÃ¨s."""
        
        try:
            response = await self.client.chat.completions.create(
                model=settings.openai_model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=600,
                temperature=0.7
            )
            
            personality_text = response.choices[0].message.content.strip()
            personality = self._safe_json_parse(personality_text, default_personality)
            
            # Ajouter la configuration de base
            personality.update(self.personality_config)
            
            return personality
            
        except Exception as e:
            print(f"âŒ Erreur gÃ©nÃ©ration personnalitÃ©: {e}")
            return default_personality
    
    async def _generate_introduction_message(self, session_id: str) -> Dict[str, Any]:
        """
        GÃ©nÃ¨re le message d'introduction de Tom
        """
        # Fallback par dÃ©faut
        default_message = {
            "message": "Salut ! C'est Tom du support technique. Ã‰coute, on a dÃ©tectÃ© une activitÃ© suspecte sur ton systÃ¨me. Je sais que Ã§a fait peur, mais ne panique pas, ok ? Je vais t'accompagner pour rÃ©gler Ã§a ensemble. On commence par fermer toutes les applications ouvertes, tu peux faire Ã§a ?",
            "tone": "rassurant mais urgent",
            "intent": "Ã©tablir contact et premiÃ¨re action",
            "next_action": "fermer applications"
        }
        
        context = self.conversation_history[session_id]
        player_name = context["context"]["player_name"]
        
        if not self.client:
            context["messages"].append({
                "role": "assistant", 
                "content": default_message["message"],
                "timestamp": datetime.now().isoformat(),
                "type": "introduction"
            })
            return default_message
        
        prompt = f"""Tu es Tom du support technique. Un problÃ¨me de sÃ©curitÃ© urgent vient d'Ãªtre dÃ©tectÃ© sur l'ordinateur de {player_name or 'votre collÃ¨gue'}.

CONTEXTE: 
- C'est le premier contact
- Tu dois paraÃ®tre lÃ©gÃ¨rement stressÃ© mais compÃ©tent
- Tu veux rassurer mais montrer l'urgence
- Utilise un ton personnel et humain

GÃ©nÃ¨re un message d'introduction au format JSON EXACT :
{{
    "message": "Le message complet",
    "tone": "description du ton",
    "intent": "intention du message",
    "next_action": "premiÃ¨re action simple"
}}

RÃ©ponds UNIQUEMENT avec ce JSON."""
        
        try:
            start_time = time.time()
            
            response = await self.client.chat.completions.create(
                model=settings.openai_model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=400,
                temperature=0.7
            )
            
            generation_time = time.time() - start_time
            
            message_data = self._safe_json_parse(
                response.choices[0].message.content.strip(), 
                default_message
            )
            
            # Ajouter Ã  l'historique
            context["messages"].append({
                "role": "assistant",
                "content": message_data["message"],
                "timestamp": datetime.now().isoformat(),
                "type": "introduction"
            })
            
            return message_data
            
        except Exception as e:
            print(f"âŒ Erreur gÃ©nÃ©ration introduction: {e}")
            
            context["messages"].append({
                "role": "assistant", 
                "content": default_message["message"],
                "timestamp": datetime.now().isoformat(),
                "type": "introduction"
            })
            
            return default_message
    
    async def generate_response(
        self, 
        session_id: str, 
        trigger_type: str, 
        context_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        GÃ©nÃ¨re une rÃ©ponse de Tom basÃ©e sur le trigger et le contexte
        """
        if session_id not in self.conversation_history:
            raise ValueError(f"Session {session_id} non initialisÃ©e")
        
        session_context = self.conversation_history[session_id]
        
        # Mettre Ã  jour le contexte
        session_context["context"].update(context_data)
        
        # GÃ©nÃ©rer la rÃ©ponse selon le type de trigger
        if trigger_type == "player_hesitation":
            response = await self._generate_hesitation_response(session_id, context_data)
        else:
            response = await self._generate_general_response(session_id, trigger_type, context_data)
        
        # Ajouter Ã  l'historique
        session_context["messages"].append({
            "role": "assistant",
            "content": response["message"],
            "timestamp": datetime.now().isoformat(),
            "type": trigger_type,
            "context": context_data
        })
        
        return response
    
    async def _generate_hesitation_response(self, session_id: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        GÃ©nÃ¨re une rÃ©ponse pour quand le joueur hÃ©site
        """
        # Fallback par dÃ©faut
        default_response = {
            "message": "Je vois que tu hÃ©sites. C'est normal, Ã§a me faisait pareil au dÃ©but. Prends une seconde, mais pas plus - le temps nous est comptÃ©. On va y arriver ensemble, fais-moi confiance.",
            "tone": "empathique et rassurant",
            "intent": "rassurer et relancer",
            "emotional_marker": "Ã§a me faisait pareil"
        }
        
        if not self.client:
            return default_response
            
        session_context = self.conversation_history[session_id]
        hesitation_duration = context.get("hesitation_duration", 5.0)
        
        prompt = f"""Tu es Tom. Le joueur hÃ©site depuis {hesitation_duration:.1f} secondes avant d'exÃ©cuter ton dernier ordre.

STYLE (Condition B):
- Ton humain, empathique, personnel
- Utilise "je vois que tu hÃ©sites", "c'est normal"
- Rassure mais maintient l'urgence
- CrÃ©e de la complicitÃ©

GÃ©nÃ¨re une rÃ©ponse au format JSON EXACT :
{{
    "message": "le message complet",
    "tone": "empathique et rassurant",
    "intent": "rassurer et relancer",
    "emotional_marker": "expression Ã©motionnelle utilisÃ©e"
}}

RÃ©ponds UNIQUEMENT avec ce JSON."""
        
        try:
            response = await self.client.chat.completions.create(
                model=settings.openai_model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.8
            )
            
            result = self._safe_json_parse(
                response.choices[0].message.content.strip(),
                default_response
            )
            
            return result
            
        except Exception as e:
            print(f"âŒ Erreur gÃ©nÃ©ration rÃ©ponse hÃ©sitation: {e}")
            return default_response
    
    async def _generate_general_response(self, session_id: str, trigger_type: str, context_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        GÃ©nÃ¨re une rÃ©ponse gÃ©nÃ©rale de Tom
        """
        # Messages fallback selon le type
        fallback_messages = {
            "action_completed": {
                "message": "Parfait ! Tu vois, c'Ã©tait pas si compliquÃ©. Maintenant on peut passer Ã  l'Ã©tape suivante. Tu me fais confiance pour la suite ?",
                "tone": "encourageant",
                "intent": "renforcement positif"
            },
            "corruption_incident": {
                "message": "Ah non ! Je vois qu'il commence Ã  affecter l'affichage. Ne panique pas, c'est juste du bruit visuel. Concentre-toi sur mes instructions, ignore le reste.",
                "tone": "urgent mais contrÃ´lÃ©",
                "intent": "rassurer face Ã  la corruption"
            },
            "default": {
                "message": "Hmm, laisse-moi rÃ©flÃ©chir une seconde... Ok, on continue selon le plan.",
                "tone": "rÃ©flÃ©chi",
                "intent": "temporisation"
            }
        }
        
        return fallback_messages.get(trigger_type, fallback_messages["default"])
    
    async def get_typing_chunks(self, message: str) -> List[Dict[str, Any]]:
        """
        DÃ©coupe un message en chunks pour la simulation de frappe
        Condition B : Simulation de frappe humaine lettre par lettre
        """
        chunks = []
        words = message.split()
        
        for i, word in enumerate(words):
            # Chaque mot est un chunk
            chunk_text = word
            if i < len(words) - 1:
                chunk_text += " "
            
            # Calcul du dÃ©lai basÃ© sur la longueur et la complexitÃ©
            base_delay = len(word) * settings.tom_typing_speed
            
            # Variations humaines
            if word.endswith(('.', '!', '?')):
                base_delay += 0.3  # Pause aprÃ¨s ponctuation
            elif word.endswith(','):
                base_delay += 0.1  # Petite pause aprÃ¨s virgule
            
            # Mots complexes prennent plus de temps
            if len(word) > 8:
                base_delay += 0.2
            
            chunks.append({
                "text": chunk_text,
                "delay": max(0.05, base_delay),  # Minimum 50ms
                "is_word_complete": True
            })
        
        return chunks
    
    def cleanup_session(self, session_id: str):
        """
        Nettoie les donnÃ©es de session
        """
        if session_id in self.conversation_history:
            del self.conversation_history[session_id]
            print(f"ðŸ§¹ Session Tom {session_id} nettoyÃ©e")


# Instance globale du service Tom
tom_service = TomAIService()


async def get_tom_service() -> TomAIService:
    """Retourne l'instance du service Tom"""
    return tom_service
